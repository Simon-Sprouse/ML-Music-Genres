{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Fit UMAP To Data + Save Manifold at Low Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import joblib  # for saving the UMAP model\n",
    "\n",
    "# --- CONFIG ---\n",
    "reduced_dir = Path(\"../Results/EmbeddingDataReduced\")\n",
    "umap_dir = Path(\"../Results/EmbeddingDataUMAP\")\n",
    "umap_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# UMAP parameters (tunable by user)\n",
    "n_neighbors = 11\n",
    "min_dist = 0.1\n",
    "n_components = 10   # change to 3 if you want 3D embeddings\n",
    "metric = \"euclidean\"\n",
    "random_state = 42\n",
    "\n",
    "# --- COLLECT REDUCED BATCH FILES ---\n",
    "batch_files = sorted(reduced_dir.glob(\"batch_*.pt\"))\n",
    "print(f\"Found {len(batch_files)} reduced batch files\")\n",
    "\n",
    "# --- INIT UMAP ---\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=min_dist,\n",
    "    n_components=n_components,\n",
    "    metric=metric,\n",
    "    random_state=random_state,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# --- FIT UMAP ON ALL DATA ---\n",
    "print(\"Fitting UMAP model...\")\n",
    "# Load all batches into memory for fit (UMAP does not support partial_fit)\n",
    "all_data = []\n",
    "for f in batch_files:\n",
    "    batch_tensor = torch.load(f, weights_only=True)\n",
    "    all_data.append(batch_tensor.numpy())\n",
    "all_data = np.vstack(all_data)\n",
    "print(f\"Total data for UMAP fit: {all_data.shape}\")\n",
    "\n",
    "umap_model.fit(all_data)\n",
    "print(\"UMAP model trained.\")\n",
    "\n",
    "# --- SAVE UMAP MODEL ---\n",
    "joblib.dump(umap_model, umap_dir / \"umap_model.pkl\")\n",
    "print(\"Saved UMAP model.\")\n",
    "\n",
    "# --- TRANSFORM & SAVE EACH BATCH ---\n",
    "for f in batch_files:\n",
    "    print(f\"Transforming {f.name} ...\")\n",
    "    batch_tensor = torch.load(f, weights_only=True)\n",
    "    reduced = umap_model.transform(batch_tensor.numpy())\n",
    "    reduced_tensor = torch.from_numpy(reduced).to(torch.float32)\n",
    "\n",
    "    out_file = umap_dir / f.name\n",
    "    torch.save(reduced_tensor, out_file)\n",
    "    print(f\"Saved UMAP batch to {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Test UMAP data was saved properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG ---\n",
    "reduced_dir = Path(\"../Results/EmbeddingDataUMAP\")\n",
    "\n",
    "# --- CHECK ---\n",
    "reduced_files = sorted(reduced_dir.glob(\"batch_*.pt\"))\n",
    "if reduced_files:\n",
    "    first_file = reduced_files[0]\n",
    "    print(f\"Loading {first_file.name} ...\")\n",
    "    reduced_tensor = torch.load(first_file, weights_only=True)\n",
    "\n",
    "    print(f\"Type: {type(reduced_tensor)}\")\n",
    "    print(f\"Shape: {reduced_tensor.shape}\")\n",
    "    print(f\"Dtype: {reduced_tensor.dtype}\")\n",
    "    print(f\"First 3 rows:\\n{reduced_tensor[:3]}\")\n",
    "    print(f\"Min/max values: {reduced_tensor.min().item():.6f} / {reduced_tensor.max().item():.6f}\")\n",
    "else:\n",
    "    print(\"No reduced batch files found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Run HDBSCAN To Detect Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # registers 3D projection\n",
    "import hdbscan\n",
    "from collections import Counter\n",
    "\n",
    "# --- CONFIG ---\n",
    "umap_dir = Path(\"../Results/EmbeddingDataUMAP\")\n",
    "\n",
    "# --- LOAD ALL BATCHES ---\n",
    "batch_files = sorted(umap_dir.glob(\"batch_*.pt\"))\n",
    "all_embeds = []\n",
    "\n",
    "for f in batch_files:\n",
    "    print(f\"Loading {f.name} ...\")\n",
    "    batch_tensor = torch.load(f, weights_only=True)\n",
    "    all_embeds.append(batch_tensor.numpy())\n",
    "\n",
    "all_embeds = np.vstack(all_embeds)  # shape: (total_points, n_dim)\n",
    "print(\"Final shape:\", all_embeds.shape)\n",
    "\n",
    "# --- RUN HDBSCAN ---\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=30,  # smaller clusters allowed\n",
    "    min_samples=10        # fewer points needed to avoid noise\n",
    ")\n",
    "cluster_labels = clusterer.fit_predict(all_embeds)\n",
    "counts = Counter(cluster_labels)\n",
    "\n",
    "\n",
    "# --- SUMMARY STATISTICS ---\n",
    "total_points = len(cluster_labels)\n",
    "noise_points = counts.get(-1, 0)\n",
    "\n",
    "# Exclude noise for cluster size stats\n",
    "cluster_sizes = [count for cid, count in counts.items() if cid != -1]\n",
    "num_clusters = len(cluster_sizes)\n",
    "mean_size = np.mean(cluster_sizes) if cluster_sizes else 0\n",
    "std_size = np.std(cluster_sizes) if cluster_sizes else 0\n",
    "noise_pct = (noise_points / total_points) * 100\n",
    "\n",
    "\n",
    "print(f\"Total points: {total_points}\")\n",
    "print(f\"Noise points: {noise_points}\")\n",
    "print(f\"Noise percentage: {noise_pct:.2f}%\")\n",
    "print(f\"Clusters found (excluding noise): {num_clusters}\")\n",
    "print(f\"Mean cluster size: {mean_size:.2f}\")\n",
    "print(f\"Std cluster size: {std_size:.2f}\")\n",
    "print(f\"Max cluster size: {max(cluster_sizes)}\")\n",
    "print(f\"Min cluster size: {min(cluster_sizes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Prep ---\n",
    "cluster_sizes = [count for cid, count in counts.items() if cid != -1]\n",
    "cluster_ids = [cid for cid in counts.keys() if cid != -1]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Histogram of cluster sizes\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cluster_sizes, bins=30, edgecolor=\"black\")\n",
    "plt.xlabel(\"Cluster size\")\n",
    "plt.ylabel(\"Number of clusters\")\n",
    "plt.title(\"Histogram of Cluster Sizes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 2. PDF (density estimate) of cluster sizes\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "counts_hist, bins = np.histogram(cluster_sizes, bins=30, density=True)\n",
    "bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "plt.plot(bin_centers, counts_hist, drawstyle=\"steps-mid\")\n",
    "plt.xlabel(\"Cluster size\")\n",
    "plt.ylabel(\"Probability density\")\n",
    "plt.title(\"Approximate PDF of Cluster Sizes\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Randomized 2D Bubble Chart (biggest clusters first)\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Sort clusters by size (largest first)\n",
    "sorted_sizes = sorted(cluster_sizes, reverse=True)\n",
    "\n",
    "# Random positions for each cluster\n",
    "rng = np.random.default_rng(seed=42)  # reproducible random layout\n",
    "x = rng.uniform(0, 100, len(sorted_sizes))\n",
    "y = rng.uniform(0, 100, len(sorted_sizes))\n",
    "\n",
    "# Bubble radii scaled by cluster size\n",
    "scale_factor = 0.5  # adjust this for bigger/smaller bubbles\n",
    "bubble_sizes = np.array(sorted_sizes) * scale_factor\n",
    "\n",
    "plt.scatter(x, y, s=bubble_sizes, alpha=0.5, c=\"tab:blue\", edgecolors=\"black\")\n",
    "\n",
    "plt.xlabel(\"Random X\")\n",
    "plt.ylabel(\"Random Y\")\n",
    "plt.title(\"Random Bubble Plot of Cluster Sizes (largest clusters drawn bigger)\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# T-SNE to 3d for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401, registers 3D projection\n",
    "from sklearn.manifold import TSNE\n",
    "import hdbscan\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "# --- RUN TSNE TO 3D ---\n",
    "print(\"Running t-SNE to 3D...\")\n",
    "tsne = TSNE(\n",
    "    n_components=3,\n",
    "    random_state=42,\n",
    "    perplexity=30,\n",
    "    init=\"pca\",\n",
    "    learning_rate=\"auto\"\n",
    ")\n",
    "embeds_3d = tsne.fit_transform(all_embeds)\n",
    "print(\"t-SNE shape:\", embeds_3d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3D PLOT WITH CLUSTER COLORS ---\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Use cluster labels as colors (noise = gray)\n",
    "colors = np.where(cluster_labels == -1, -999, cluster_labels)\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    embeds_3d[:, 0],\n",
    "    embeds_3d[:, 1],\n",
    "    embeds_3d[:, 2],\n",
    "    c=colors,\n",
    "    cmap=\"tab20\",\n",
    "    s=2,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"t-SNE-1\")\n",
    "ax.set_ylabel(\"t-SNE-2\")\n",
    "ax.set_zlabel(\"t-SNE-3\")\n",
    "ax.set_title(\"t-SNE Projection Colored by HDBSCAN Clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FILTER NON-NOISE POINTS ---\n",
    "mask = cluster_labels != -1\n",
    "embeds_3d_non_noise = embeds_3d[mask]\n",
    "labels_non_noise = cluster_labels[mask]\n",
    "\n",
    "# --- 3D PLOT WITH CLUSTER COLORS (NON-NOISE ONLY) ---\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    embeds_3d_non_noise[:, 0],\n",
    "    embeds_3d_non_noise[:, 1],\n",
    "    embeds_3d_non_noise[:, 2],\n",
    "    c=labels_non_noise,\n",
    "    cmap=\"tab20\",\n",
    "    s=2,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"t-SNE-1\")\n",
    "ax.set_ylabel(\"t-SNE-2\")\n",
    "ax.set_zlabel(\"t-SNE-3\")\n",
    "ax.set_title(\"t-SNE Projection (Non-Noise HDBSCAN Clusters)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CHOOSE TOP-K CLUSTERS ---\n",
    "k = 40  # change this as needed\n",
    "\n",
    "# Count cluster sizes\n",
    "unique_labels, counts = np.unique(cluster_labels[cluster_labels != -1], return_counts=True)\n",
    "sorted_clusters = [lab for lab, _ in sorted(zip(unique_labels, counts), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "# Keep only top-k\n",
    "top_k_clusters = set(sorted_clusters[:k])\n",
    "\n",
    "mask = np.isin(cluster_labels, list(top_k_clusters))\n",
    "embeds_3d_topk = embeds_3d[mask]\n",
    "labels_topk = cluster_labels[mask]\n",
    "\n",
    "# --- 3D PLOT WITH CLUSTER COLORS (TOP-K ONLY) ---\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    embeds_3d_topk[:, 0],\n",
    "    embeds_3d_topk[:, 1],\n",
    "    embeds_3d_topk[:, 2],\n",
    "    c=labels_topk,\n",
    "    cmap=\"tab20\",\n",
    "    s=2,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"t-SNE-1\")\n",
    "ax.set_ylabel(\"t-SNE-2\")\n",
    "ax.set_zlabel(\"t-SNE-3\")\n",
    "ax.set_title(f\"t-SNE Projection (Top {k} Largest HDBSCAN Clusters)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # registers 3D projection\n",
    "\n",
    "# --- CONFIG ---\n",
    "umap_dir = Path(\"../Results/EmbeddingDataUMAP\")\n",
    "\n",
    "# --- LOAD ALL BATCHES ---\n",
    "batch_files = sorted(umap_dir.glob(\"batch_*.pt\"))\n",
    "all_embeds = []\n",
    "\n",
    "\n",
    "for f in batch_files:\n",
    "    print(f\"Loading {f.name} ...\")\n",
    "    batch_tensor = torch.load(f, weights_only=True)\n",
    "    all_embeds.append(batch_tensor.numpy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_embeds = np.vstack(all_embeds)\n",
    "# Center and scale each axis\n",
    "all_embeds = (all_embeds - all_embeds.mean(axis=0)) / all_embeds.std(axis=0)\n",
    "\n",
    "# --- 3D SCATTER PLOT ---\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "x, y, z = all_embeds[:, 0], all_embeds[:, 1], all_embeds[:, 2]\n",
    "\n",
    "ax.scatter(x, y, z, s=1, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"UMAP-1\")\n",
    "ax.set_ylabel(\"UMAP-2\")\n",
    "ax.set_zlabel(\"UMAP-3\")\n",
    "ax.set_title(\"3D UMAP Embeddings\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cnn-embeddings)",
   "language": "python",
   "name": "cnn-embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
