{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrubberband as pyrb\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import madmom\n",
    "print(pyrb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Songs/bob_marley--redemption_song.mp3\"\n",
    "y, sr = librosa.load(filename, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process with madmom's RNN downbeat processor\n",
    "proc = madmom.features.downbeats.RNNDownBeatProcessor()(filename)\n",
    "\n",
    "# Decode with a DBN to get sequences of [beat, downbeat]\n",
    "beats = madmom.features.downbeats.DBNDownBeatTrackingProcessor(beats_per_bar=[3, 4],\n",
    "                                                               fps=100)(proc)\n",
    "\n",
    "# beats is an array of shape (N, 2):\n",
    "#   [:,0] = time (s)\n",
    "#   [:,1] = 1 if downbeat, 0 if beat\n",
    "\n",
    "# Extract beat times and downbeat times\n",
    "beat_times = beats[:,0]\n",
    "downbeat_times = beats[beats[:,1] == 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def make_downbeat_aligned_images(y, sr, downbeat_times, time_bins_per_downbeat=32, downbeats_in_image=4):\n",
    "    \"\"\"\n",
    "    Create log-mel spectrogram images aligned to downbeats.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "        Audio signal.\n",
    "    sr : int\n",
    "        Sampling rate.\n",
    "    downbeat_times : list of float\n",
    "        Times (in seconds) of detected downbeats.\n",
    "    time_bins_per_downbeat : int\n",
    "        Number of spectrogram frames allocated between two downbeats.\n",
    "    downbeats_in_image : int\n",
    "        How many downbeats per image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images : list of np.ndarray\n",
    "        Each image has shape (128, time_bins_per_downbeat * downbeats_in_image).\n",
    "    \"\"\"\n",
    "    # Compute mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Map downbeat times -> spectrogram frames\n",
    "    hop_length = 512\n",
    "    frame_times = librosa.frames_to_time(np.arange(S_db.shape[1]), sr=sr, hop_length=hop_length)\n",
    "    downbeat_frames = np.searchsorted(frame_times, downbeat_times)\n",
    "\n",
    "    segments = []\n",
    "    for i in range(len(downbeat_frames) - 1):\n",
    "        start, end = downbeat_frames[i], downbeat_frames[i + 1]\n",
    "        segment = S_db[:, start:end]\n",
    "\n",
    "        if segment.shape[1] < 2:\n",
    "            continue\n",
    "\n",
    "        # Resample along time axis to exactly time_bins_per_downbeat\n",
    "        x_old = np.linspace(0, 1, segment.shape[1])\n",
    "        x_new = np.linspace(0, 1, time_bins_per_downbeat)\n",
    "        segment_resampled = np.vstack([\n",
    "            np.interp(x_new, x_old, row) for row in segment\n",
    "        ])\n",
    "\n",
    "        segments.append(segment_resampled)\n",
    "\n",
    "    # Group consecutive segments into images\n",
    "    images = []\n",
    "    for i in range(0, len(segments) - downbeats_in_image + 1, downbeats_in_image):\n",
    "        image = np.hstack(segments[i:i + downbeats_in_image])\n",
    "        images.append(image)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# y, sr = librosa.load(\"song.wav\", sr=None)\n",
    "# downbeat_times = [0.0, 1.0, 2.0, 3.0, 4.0]  # dummy\n",
    "imgs = make_downbeat_aligned_images(y, sr, downbeat_times, time_bins_per_downbeat=32, downbeats_in_image=4)\n",
    "print(len(imgs), imgs[0].shape)  # -> (N, (128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test_env)",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
