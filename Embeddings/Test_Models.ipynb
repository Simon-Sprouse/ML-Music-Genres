{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "\n",
    "# Utility: freeze params\n",
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "# 1. ResNet-34\n",
    "resnet34 = freeze_model(models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1))\n",
    "print(\"ResNet-34 loaded:\", sum(p.numel() for p in resnet34.parameters())/1e6, \"M params\")\n",
    "\n",
    "# 2. InceptionV3\n",
    "inception = freeze_model(models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1))\n",
    "print(\"InceptionV3 loaded:\", sum(p.numel() for p in inception.parameters())/1e6, \"M params\")\n",
    "\n",
    "# 3. SqueezeNet 1.1\n",
    "squeezenet = freeze_model(models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.IMAGENET1K_V1))\n",
    "print(\"SqueezeNet loaded:\", sum(p.numel() for p in squeezenet.parameters())/1e6, \"M params\")\n",
    "\n",
    "# 4. EfficientNetV2-S (via timm)\n",
    "efficientnetv2s = freeze_model(timm.create_model(\"tf_efficientnetv2_s_in21k\", pretrained=True))\n",
    "print(\"EfficientNetV2-S loaded:\", sum(p.numel() for p in efficientnetv2s.parameters())/1e6, \"M params\")\n",
    "\n",
    "# 5. MobileNetV3-Small\n",
    "mobilenetv3s = freeze_model(models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1))\n",
    "print(\"MobileNetV3-Small loaded:\", sum(p.numel() for p in mobilenetv3s.parameters())/1e6, \"M params\")\n",
    "\n",
    "print(\"\\nâœ… All models loaded and frozen successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming models are already loaded and frozen:\n",
    "# resnet34, inception, squeezenet, efficientnetv2s, mobilenetv3s\n",
    "\n",
    "# Preprocessing transforms\n",
    "preprocess_224 = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "preprocess_299 = transforms.Compose([\n",
    "    transforms.Resize(320),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_embeddings(image_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Run an image through all five frozen models and return embeddings.\n",
    "    Returns a dictionary of tensors keyed by model name.\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    embeddings = {}\n",
    "    \n",
    "    # Set all models to eval mode and freeze parameters\n",
    "    resnet34.eval()\n",
    "    inception.eval()\n",
    "    squeezenet.eval()\n",
    "    efficientnetv2s.eval()\n",
    "    mobilenetv3s.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # ResNet-34 - Remove final FC layer\n",
    "        x = preprocess_224(img).unsqueeze(0).to(device)\n",
    "        resnet34_feat = torch.flatten(torch.nn.Sequential(*list(resnet34.children())[:-1])(x), 1)\n",
    "        embeddings['resnet34'] = resnet34_feat\n",
    "        \n",
    "        # InceptionV3 - Use forward pass and extract features before final FC\n",
    "        x = preprocess_299(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Method 1: Replace the fc layer temporarily\n",
    "        original_fc = inception.fc\n",
    "        inception.fc = nn.Identity()\n",
    "        inception_feat = inception(x)\n",
    "        inception.fc = original_fc  # Restore original\n",
    "        embeddings['inceptionv3'] = inception_feat\n",
    "       \n",
    "        \n",
    "        # SqueezeNet 1.1 - Use features only\n",
    "        x = preprocess_224(img).unsqueeze(0).to(device)\n",
    "        squeezenet_feat = torch.flatten(squeezenet.features(x), 1)\n",
    "        embeddings['squeezenet'] = squeezenet_feat\n",
    "        \n",
    "        # EfficientNetV2-S - Use forward_features method\n",
    "        x = preprocess_224(img).unsqueeze(0).to(device)\n",
    "        effnet_feat = torch.flatten(efficientnetv2s.forward_features(x), 1)\n",
    "        embeddings['efficientnetv2s'] = effnet_feat\n",
    "        \n",
    "        # MobileNetV3-Small - Use features only\n",
    "        x = preprocess_224(img).unsqueeze(0).to(device)\n",
    "        mobilenet_feat = torch.flatten(mobilenetv3s.features(x), 1)\n",
    "        embeddings['mobilenetv3_small'] = mobilenet_feat\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Test the function\n",
    "filename = \"../Results/Dev/rock.00069/aligned_spectrogram_21.png\"\n",
    "embeds = get_embeddings(filename, device='cpu')\n",
    "print(embeds['resnet34'].shape)\n",
    "print(embeds['squeezenet'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cnn-embeddings)",
   "language": "python",
   "name": "cnn-embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
