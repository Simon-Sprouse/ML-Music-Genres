{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def get_all_aligned_spectrograms(base_dir):\n",
    "    \"\"\"\n",
    "    Search recursively under base_dir for files of the form \n",
    "    aligned_spectrogram_<n>.png. \n",
    "    Returns a list of all matches sorted first by folder, \n",
    "    then numerically by <n>.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(base_dir, \"*\", \"aligned_spectrogram_*.png\")\n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    def sort_key(path):\n",
    "        folder = os.path.dirname(path)\n",
    "        idx = int(os.path.splitext(path)[0].split('_')[-1])\n",
    "        return (folder, idx)\n",
    "\n",
    "    files.sort(key=sort_key)\n",
    "    return files\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "base_dir = \"../Results/Dev\"\n",
    "filenames = get_all_aligned_spectrograms(base_dir)\n",
    "\n",
    "print(f\"Found {len(filenames)} files\")\n",
    "print(filenames[:20])  # show first 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_pca_incremental.py\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def image_paths_from_list(filenames):\n",
    "    return filenames  # assume filenames is a list you already generated\n",
    "\n",
    "def build_memmap(image_paths, memmap_path, img_size=(128, 128), dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Create a memmap of shape (N, D) where D = H*W, grayscale and flattened.\n",
    "    \"\"\"\n",
    "    N = len(image_paths)\n",
    "    H, W = img_size\n",
    "    D = H * W\n",
    "    os.makedirs(os.path.dirname(memmap_path), exist_ok=True)\n",
    "    mm = np.memmap(memmap_path, dtype=dtype, mode='w+', shape=(N, D))\n",
    "    for i, p in enumerate(tqdm(image_paths, desc=\"Writing memmap\")):\n",
    "        img = Image.open(p).convert('L').resize((W, H), Image.BILINEAR)\n",
    "        arr = np.asarray(img, dtype=dtype).reshape(-1) / 255.0\n",
    "        mm[i, :] = arr\n",
    "    mm.flush()\n",
    "    return memmap_path, (N, D)\n",
    "\n",
    "def run_incremental_pca(memmap_path, shape, n_components=100, batch_size=64, save_path=\"pixel_pca.npz\"):\n",
    "    N, D = shape\n",
    "    mm = np.memmap(memmap_path, dtype=np.float32, mode='r', shape=(N, D))\n",
    "\n",
    "    ipca = IncrementalPCA(n_components=n_components)\n",
    "    # First pass: fit in batches to compute principal components\n",
    "    for start in tqdm(range(0, N, batch_size), desc=\"IPCA fit\"):\n",
    "        batch = mm[start:start+batch_size]\n",
    "        ipca.partial_fit(batch)\n",
    "    # Optionally transform all data (second pass)\n",
    "    components = ipca.components_          # shape (n_components, D)\n",
    "    mean = ipca.mean_                      # shape (D,)\n",
    "    explained = ipca.explained_variance_ratio_\n",
    "\n",
    "    np.savez_compressed(save_path,\n",
    "                        components=components,\n",
    "                        mean=mean,\n",
    "                        explained=explained,\n",
    "                        n_components=n_components)\n",
    "    print(f\"Saved PCA data to {save_path}\")\n",
    "    return ipca\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # assume filenames is a list of filepaths (numeric-sorted)\n",
    "    from glob import glob\n",
    "    memmap_path = \"../Results/EmbeddingData/pixel_memmap.dat\"\n",
    "    memmap_path, shape = build_memmap(filenames, memmap_path, img_size=(128,128))\n",
    "    ipca = run_incremental_pca(memmap_path, shape, n_components=50, batch_size=64, save_path=\"../Results/EmbeddingData/pixel_pca.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.load(\"../Results/EmbeddingData/pixel_pca.npz\")\n",
    "comps = data[\"components\"]  # (k, D)\n",
    "H, W = 128, 128\n",
    "k = 10\n",
    "fig, axs = plt.subplots(1, k, figsize=(15,3))\n",
    "for i in range(k):\n",
    "    face = comps[i].reshape(H, W)\n",
    "    axs[i].imshow((face - face.min())/(face.max()-face.min()), cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def get_aligned_spectrograms(prefix):\n",
    "    \"\"\"\n",
    "    Given a prefix like '../Results/Dev/rock.00069/aligned_spectrogram',\n",
    "    return all matching files of the form aligned_spectrogram_<n>.png,\n",
    "    sorted numerically by <n>.\n",
    "    \"\"\"\n",
    "    pattern = f\"{prefix}_*.png\"\n",
    "    files = glob.glob(pattern)\n",
    "    files.sort(key=lambda x: int(os.path.splitext(x)[0].split('_')[-1]))\n",
    "    return files\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "prefix = \"../Results/Dev/rock.00069/aligned_spectrogram\"\n",
    "filenames = get_aligned_spectrograms(prefix)\n",
    "\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_pca_inference_matrix.py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def load_pca(npz_path):\n",
    "    \"\"\"Reload trained PCA from .npz file.\"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    components = data[\"components\"]      # (n_components, D)\n",
    "    mean = data[\"mean\"]                  # (D,)\n",
    "    n_components = int(data[\"n_components\"])\n",
    "    return components, mean, n_components\n",
    "\n",
    "def project_images_matrix(filenames, pca_npz_path, save_path=\"pixel_embeddings.pt\", img_size=(128,128)):\n",
    "    H, W = img_size\n",
    "\n",
    "    # Load PCA weights\n",
    "    components, mean, n_components = load_pca(pca_npz_path)\n",
    "\n",
    "    all_embeds = []\n",
    "\n",
    "    for fn in tqdm(filenames, desc=\"Projecting images\"):\n",
    "        # Load + preprocess image\n",
    "        img = Image.open(fn).convert(\"L\").resize((W, H), Image.BILINEAR)\n",
    "        arr = np.asarray(img, dtype=np.float32).reshape(-1) / 255.0\n",
    "\n",
    "        # Center and project\n",
    "        arr_centered = arr - mean\n",
    "        embed = np.dot(components, arr_centered)   # shape (n_components,)\n",
    "\n",
    "        all_embeds.append(embed)\n",
    "\n",
    "    # Stack into (N, n_components)\n",
    "    embeddings_tensor = torch.tensor(np.stack(all_embeds), dtype=torch.float32)\n",
    "\n",
    "    # Save tensor\n",
    "    torch.save(embeddings_tensor, save_path)\n",
    "    print(f\"Saved embeddings to {save_path}, shape={embeddings_tensor.shape}\")\n",
    "\n",
    "    return embeddings_tensor\n",
    "\n",
    "\n",
    "\n",
    "embeddings = project_images_matrix(\n",
    "    filenames,\n",
    "    pca_npz_path=\"../Results/EmbeddingData/pixel_pca.npz\",\n",
    "    img_size=(128,128)\n",
    ")\n",
    "print(embeddings.shape)  # e.g. torch.Size([27, 512])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cnn-embeddings)",
   "language": "python",
   "name": "cnn-embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
